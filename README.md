<a name="leap"></a>

# LEAP: Logical Embodied Action Planning for Long-Horizon Robotic Tasks via Generative Vision-Language Alignment

<p align="center">
  <a href="https://huggingface.co/EvanSirius/leap-ckpts"><img src="https://img.shields.io/badge/ğŸ¤—%20Model-leap--ckpts-blue" alt="Model"></a>
  <a href="https://huggingface.co/datasets/EvanSirius/leap-agibot-processed"><img src="https://img.shields.io/badge/ğŸ¤—%20Dataset-leap--agibot--processed-green" alt="Dataset"></a>
  <a href="https://github.com/OpenMOSS/VLABench"><img src="https://img.shields.io/badge/Benchmark-VLABench-orange" alt="VLABench"></a>
</p>

## 1. ä»‹ç» Â· Introduction

**LEAP** èšç„¦å¤šæ¨¡æ€æœºå™¨äººä»»åŠ¡è§„åˆ’ï¼Œå›´ç»• **Qwen3-VL-2B-Instruct** æ„å»ºå…¨å‚å¾®è°ƒã€VLABench å…­ç»´åº¦è¯„æµ‹ä¸ LLM-as-a-Judge ç›²å®¡æµç¨‹ã€‚å½“å‰ç‰ˆæœ¬æ—¨åœ¨æä¾›å¯å¤ç°å®éªŒè„šæœ¬ï¼Œä¾¿äºç ”ç©¶è€…éªŒè¯å’Œæ‰©å±•ä»¥ä¸‹èƒ½åŠ›ï¼š

- Memory & Tasksã€CommonSenseã€Semanticã€Spatialã€PhysicsLawã€Complex å…­ä¸ªç»´åº¦çš„ç»Ÿä¸€è¯„æµ‹ã€‚
- è®­ç»ƒã€è¯„æµ‹ã€ç›²å®¡ã€å¯è§†åŒ–è„šæœ¬çš„æ ‡å‡†åŒ–ç»„ç»‡ï¼Œé™ä½è·¨åœºæ™¯å¤ç°é—¨æ§›ã€‚
- LOVE-Agibot-Beta ç­‰å…¬å¼€æ•°æ®çš„ä¸‹è½½ã€æ¸…æ´—ä¸é¦–å¸§æå–å·¥å…·ã€‚

## 2. ä»“åº“ç»“æ„ Â· Repository Structure

```text
LEAP/
â”œâ”€â”€ configs/        # å…¨å±€è·¯å¾„ã€è®­ç»ƒ/è¯„æµ‹å¸¸é‡ï¼ˆWorkspaceConfigï¼‰
â”œâ”€â”€ data/           # JSONLã€LOVE-Agibot å›¾åƒ
â”œâ”€â”€ dataset/        # vlm_evaluation_v1.0ï¼ˆæŒ‰ CommonSense/Complex/... ç»´åº¦æ‹†åˆ†ï¼‰
â”œâ”€â”€ logs/           # å„ç»´åº¦è¯„æµ‹æ—¥å¿—ä¸ PID è®°å½•
â”œâ”€â”€ models/         # HuggingFace æœ¬åœ°ç¼“å­˜ï¼ˆå¦‚ Qwen3-VL-2B-Instructï¼‰
â”œâ”€â”€ output/         # è®­ç»ƒ checkpoint-* ä¸æœ€ç»ˆæƒé‡
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download/   # æ¨¡å‹ & VLABench ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ training/   # run-finetuning.pyã€run-training.sh å…¨é‡å¾®è°ƒå…¥å£
â”‚   â”œâ”€â”€ ablation/   # LoRA æ¶ˆèå®éªŒè„šæœ¬ï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰
â”‚   â”œâ”€â”€ evaluation/ # VLABench/LLM-Judge/å¯è§†åŒ–è„šæœ¬
â”‚   â””â”€â”€ utils/      # æ•°æ®æ¸…æ´—ã€LOVE-Agibot å¤„ç†
â”œâ”€â”€ VLABench/       # å®˜æ–¹è¯„æµ‹å­æ¨¡å—ï¼ˆéœ€æ‰§è¡Œ git submodule update --initï¼‰
â”œâ”€â”€ eva_results/    # æœ€æ–°è¯„æµ‹ç»“æœï¼ŒæŒ‰ç»´åº¦/æ¨¡å‹åˆ†å±‚
â”œâ”€â”€ qwen-ft-env.yml # Conda ç¯å¢ƒå®šä¹‰
â””â”€â”€ README.md
```

## 3. å¿«é€Ÿå¼€å§‹ Â· Quick Start

### 3.1 å…‹éš†ä»“åº“

```bash
# åŒ…å« VLABench å­æ¨¡å—
git clone --recursive https://github.com/Evan-Joseph/leap-code.git
cd leap-code

# å¦‚æœå¿˜è®° --recursiveï¼Œå¯ä»¥åç»­æ‰§è¡Œï¼š
git submodule update --init --recursive
```

### 3.2 ç¯å¢ƒå‡†å¤‡

```bash
conda env create -f qwen-ft-env.yml
conda activate qwen-ft-env
```

### 3.3 ä¸‹è½½æ¨¡å‹ä¸æ•°æ®

```bash
# 1) è·å– Qwen3-VL-2B-Instructï¼ˆè„šæœ¬å†…ç½® hf-mirror åŠ é€Ÿï¼Œä¿®å¤äº†ç»å¯¹è·¯å¾„é—®é¢˜ï¼‰
bash scripts/download/download_model.sh

# 2) ä¸‹è½½ VLABench è¯„æµ‹é›†ï¼ˆä¼˜åŒ–äº†é™æµé‡è¯•é€»è¾‘ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
python scripts/download/download_vlabench_with_retry.py

# 3) éªŒè¯ VLABench æ•°æ®å®Œæ•´æ€§ï¼ˆæ–°å¢éªŒè¯è„šæœ¬ï¼Œç¡®ä¿ä¸‹è½½æ— æŸï¼‰
python scripts/utils/verify_dataset.py

# 4) ï¼ˆå¯é€‰ï¼‰ä¸‹è½½ LEAP é¢„å¤„ç†æ•°æ®é›†
huggingface-cli download EvanSirius/leap-agibot-processed --local-dir data/
```

### 3.4 å…¨å‚å¾®è°ƒç¤ºä¾‹

```bash
bash scripts/training/run-training.sh
```

è„šæœ¬é»˜è®¤æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. æ ¹æ® `scripts/` ä¸Šçº§ç›®å½•å®šä½ä»“åº“æ ¹è·¯å¾„ã€‚
2. è¯»å– `data/train_151230.jsonl` ä¸ `models/Qwen3-VL-2B-Instruct/`ã€‚
3. ä»¥ BF16ã€SDPA æ³¨æ„åŠ›å’Œ 6Ã—6 çš„æ¢¯åº¦ç´¯ç§¯å¼€å±•è®­ç»ƒï¼Œå¹¶å°† checkpoint å†™å…¥ `output/`ã€‚

### 3.5 LoRA å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆæ¶ˆèå®éªŒï¼‰

```bash
# ä½¿ç”¨é»˜è®¤ standard é¢„è®¾
bash scripts/ablation/run-lora-training.sh

# ä½¿ç”¨æŒ‡å®šé¢„è®¾ï¼ˆlight/standard/full/aggressiveï¼‰
bash scripts/ablation/run-lora-training.sh --preset full

# æ‰¹é‡è¿è¡Œå¤šç§é…ç½®è¿›è¡Œæ¶ˆèå®éªŒ
bash scripts/ablation/run-ablation-experiments.sh
```

LoRA é¢„è®¾é…ç½®è¯´æ˜ï¼š
- `light`: r=8, æœ€å°åŒ–å‚æ•°ï¼Œé€‚åˆå¿«é€ŸéªŒè¯
- `standard`: r=16, æ ‡å‡†é…ç½®ï¼Œå¹³è¡¡æ•ˆæœä¸æ•ˆç‡
- `full`: r=32, è¦†ç›–æ›´å¤šå±‚ï¼Œæ¥è¿‘å…¨é‡å¾®è°ƒæ•ˆæœ
- `aggressive`: r=64, é«˜ç§© LoRAï¼Œæœ€å¤§åŒ–è¡¨è¾¾èƒ½åŠ›

### 3.6 VLABench å¤šç»´åº¦è¯„æµ‹

```bash
# å…¨ç»´åº¦ï¼ˆM&T/CommonSense/.../Complexï¼‰æ‰¹é‡è¯„æµ‹
python scripts/evaluation/run_vlm_evaluation.py \
	--checkpoint output/checkpoint-200 \
	--dimension all

# å•ç‹¬è·‘ M&T
python scripts/evaluation/run_vlm_evaluation.py \
	--checkpoint output/checkpoint-200 \
	--dimension "M&T"

# Blind-10 LLM-as-a-Judge æµæ°´çº¿
python scripts/evaluation/run_vlm_output.py --baseline_model models/Qwen3-VL-2B-Instruct
python scripts/evaluation/analyze_output_results.py
```

## 4. ç»“æœä¸å¯è§†åŒ– Â· Results

| Model | M&T â†‘ | CommonSense â†‘ | Semantic â†‘ | Spatial â†‘ | PhysicalLaw â†‘ | Complex â†‘ | Avg â†‘ |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Qwen3-VL-2B-Baseline | 29.60 | 25.70 | 25.89 | 31.10 | 24.00 | 14.28 | 25.10 |
| **LEAP (checkpoint-5000)** | **32.96** | **27.27** | **28.49** | **31.62** | **30.27** | **19.67** | **28.38** |
| Improvement | +11.3% | +6.1% | +10.0% | +1.7% | +26.1% | +37.7% | **+13.1%** |

> æ•°æ®æ¥æºï¼š`eva_results/<dimension>/<model>/final_score.json` ä¸­ `total_score` çš„å‡å€¼ï¼›å›¾åƒå¯é€šè¿‡ `scripts/evaluation/draw_*.py` ç”Ÿæˆã€‚

## 5. æ•°æ®ä¸æ¨¡å‹ Â· Datasets & Models

| èµ„æº | é“¾æ¥ | è¯´æ˜ |
| --- | --- | --- |
| **LEAP Checkpoints** | [ğŸ¤— EvanSirius/leap-ckpts](https://huggingface.co/EvanSirius/leap-ckpts) | å…¨é‡å¾®è°ƒæƒé‡ (checkpoint-200 ~ checkpoint-7000) |
| **LEAP Dataset** | [ğŸ¤— EvanSirius/leap-agibot-processed](https://huggingface.co/datasets/EvanSirius/leap-agibot-processed) | è®­ç»ƒé›†ã€æµ‹è¯•é›†ã€ç›²è¯„é›† |
| **VLABench** | [GitHub OpenMOSS/VLABench](https://github.com/OpenMOSS/VLABench) | å®˜æ–¹è¯„æµ‹æ¡†æ¶ï¼ˆGit Submoduleï¼‰ |
| **åŸºåº§æ¨¡å‹** | [ğŸ¤— Qwen/Qwen3-VL-2B-Instruct](https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct) | Qwen3-VL 2B æŒ‡ä»¤å¾®è°ƒç‰ˆ |

## 6. Citation & Acknowledgement

```bibtex
@article{zhang2024vlabench,
	title={VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks},
	author={Shiduo Zhang and Zhe Xu and Peiju Liu and others},
	journal={arXiv preprint arXiv:2412.18194},
	year={2024}
}

@article{bai2025qwen3vl,
	title={Qwen3-VL Technical Report},
	author={Shuai Bai and Yuxuan Cai and Ruizhe Chen and others},
	journal={arXiv preprint arXiv:2511.21631},
	year={2025}
}
```

- æ„Ÿè°¢ Qwen å›¢é˜Ÿå¼€æ”¾ Qwen3-VL ç³»åˆ—ï¼Œä½¿å¾—æœ¬ä»“åº“å¯ä»¥åœ¨å¼€æºæƒé‡ä¸Šæ„å»ºã€‚
- è‡´è°¢ VLABenchã€LOVE-Agibot ç­‰é¡¹ç›®æä¾›æ•°æ®ä¸è¯„æµ‹åŸºç¡€è®¾æ–½ã€‚

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
